// SPDX-License-Identifier: GPL-2.0
/*
 * Texas Instruments K3 AM65 Ethernet QoS submodule
 *
 * Copyright (C) 2017-2019 Texas Instruments Incorporated - http://www.ti.com/
 *
 * Enhanced Scheduler Traffic (EST - P802.1Qbv/D2.2)
 * When enabled and configured, EST allows express queue traffic to be
 * scheduled (placed) on the wire at specific repeatable time intervals. EST
 * operates on a repeating time interval generated by the CPTS EST function
 * generator. For example, a 125us repeating time interval can be configured.
 * Each Ethernet port has 128 EST fetch commands maximum in the global EST
 * fetch RAM. Each 22-bit fetch command consists of a 14-bit fetch count
 * (14 MSB’s) and an 8-bit priority fetch allow (8 LSB’s) that will be applied
 * for the fetch count time in wireside clocks. The configured port fetch
 * commands are executed in sequence, beginning at port address zero each time
 * through the time interval beginning at cycle start EST allows non-scheduled
 * express and prempt queue traffic to be cleared from the wire to ensure that
 * the scheduled traffic is transmitted at the proper time (zero allow) EST can
 * be used with or without premption. The CPSW0_PN_IET_CONTROL_REG[23-16] MAC
 * _PREMPT value determines whether the priority is enabled on the express or
 * prempt queue. Whether a priority is on the express or prempt queue only
 * effects the wire clear time from an EST operation perspective. Software
 * should not move priorities to the prempt queue unless preemption is
 * configured, enabled, and verified allowing preemption to occur. Express
 * packet time stamp events can be enabled to assist software in configuring
 * and timing EST operations.
 *
 */

#include "am65-cpsw-qos.h"
#include <net/pkt_sched.h>
#include "am65-cpsw-nuss.h"
#include <linux/time.h>

#define AM65_CPSW_REG_CTL			0x004
#define AM65_CPSW_REG_EST_TS_DOMAIN		0x054
#define AM65_CPSW_PN_REG_CTL			0x004
#define AM65_CPSW_PN_REG_MAX_BLKS		0x008
#define AM65_CPSW_PN_REG_FIFO_STATUS		0x050
#define AM65_CPSW_PN_REG_EST_CTL		0x060
#define AM65_CPSW_PN_REG_TS_CTL             	0x310

/* AM65_CPSW_REG_CTL register fields */
#define AM65_CPSW_CTL_IET_EN			BIT(17)
#define AM65_CPSW_CTL_EST_EN			BIT(18)

/* AM65_CPSW_REG_EST_TS_DOMAIN register fields */
#define AM65_CPSW_EST_TS_DOMAIN_OFFSET		0
#define AM65_CPSW_EST_TS_DOMAIN_MASK		0xf

/* AM65_CPSW_PN_REG_CTL register fields */
#define AM65_CPSW_PN_CTL_IET_PORT_EN		BIT(16)
#define AM65_CPSW_PN_CTL_EST_PORT_EN		BIT(17)

/* AM65_CPSW_PN_REG_MAX_BLKS register vals */
#define AM65_CPSW_PN_MAX_BLKS_DEF		0x00001004
#define AM65_CPSW_PN_MAX_BLKS_IET		0x00000D07

/* AM65_CPSW_PN_REG_EST_CTL register fields */
#define AM65_CPSW_PN_EST_ONEBUF			BIT(0)
#define AM65_CPSW_PN_EST_BUFSEL			BIT(1)
#define AM65_CPSW_PN_EST_TS_EN			BIT(2)
#define AM65_CPSW_PN_EST_TS_FIRST		BIT(3)
#define AM65_CPSW_PN_EST_ONEPRI			BIT(4)
#define AM65_CPSW_PN_EST_TS_PRI_OFFSET		5
#define AM65_CPSW_PN_EST_TS_PRI_MASK		0x7
#define AM65_CPSW_PN_EST_FILL_EN		BIT(8)
#define AM65_CPSW_PN_EST_FILL_MARGIN_OFFSET	16
#define AM65_CPSW_PN_EST_FILL_MARGIN_MASK	0x3ff

/* AM65_CPSW_PN_REG_FIFO_STATUS register fields */
#define AM65_CPSW_PN_FST_TX_PRI_ACTIVE_OFFSET	0
#define AM65_CPSW_PN_FST_TX_PRI_ACTIVE_MASK	0xf
#define AM65_CPSW_PN_FST_TX_E_MAC_ALLOW_OFFSET	8
#define AM65_CPSW_PN_FST_TX_E_MAC_ALLOW_MASK	0xf
#define AM65_CPSW_PN_FST_EST_CNT_ERR		BIT(16)
#define AM65_CPSW_PN_FST_EST_ADD_ERR		BIT(17)
#define AM65_CPSW_PN_FST_EST_BUFACT		BIT(18)

/* EST FETCH COMMAND RAM */
#define AM65_CPSW_PORT_RAM_BASE			0x12000
#define AM65_CPSW_FETCH_CMD_NUM			0x1F
#define AM65_CPSW_CPSW_PORT_RAM_OFFSET		(AM65_CPSW_FETCH_CMD_NUM * 4)
#define AM65_CPSW_FETCH_CNT_MASK		0x3fff
#define AM65_CPSW_FETCH_CNT_SHIFT		8
#define AM65_CPSW_FETCH_ALLOW_MASK		0xff

#define SPEED_1000				1000

static void am65_cpsw_est_enable(struct am65_cpsw_common *common, int enable)
{
	u32 val;

	val = readl(common->cpsw_base + AM65_CPSW_REG_CTL);

	if (enable)
		val |= AM65_CPSW_CTL_EST_EN;
	else
		val &= ~AM65_CPSW_CTL_EST_EN;

	writel(val, common->cpsw_base + AM65_CPSW_REG_CTL);
	common->est_enabled = enable;
}

static void am65_cpsw_iet_enable(struct am65_cpsw_common *common, int enable)
{
	u32 val;

	val = readl(common->cpsw_base + AM65_CPSW_REG_CTL);

	if (enable)
		val |= AM65_CPSW_CTL_IET_EN;
	else
		val &= ~AM65_CPSW_CTL_IET_EN;

	writel(val, common->cpsw_base + AM65_CPSW_REG_CTL);
	common->iet_enabled = enable;
}

static void am65_cpsw_port_est_enable(struct am65_cpsw_port *port, int enable)
{
	u32 val;

	val = readl(port->port_base + AM65_CPSW_PN_REG_CTL);
	if (enable)
		val |= AM65_CPSW_PN_CTL_EST_PORT_EN;
	else
		val &= ~AM65_CPSW_PN_CTL_EST_PORT_EN;

	writel(val, port->port_base + AM65_CPSW_PN_REG_CTL);
	port->est_enabled = enable;
}

static void am65_cpsw_port_iet_enable(struct am65_cpsw_port *port, int enable)
{
	u32 max_blks_val;
	u32 val;

	val = readl(port->port_base + AM65_CPSW_PN_REG_CTL);
	if (enable) {
		val |= AM65_CPSW_PN_CTL_IET_PORT_EN;
		max_blks_val = AM65_CPSW_PN_MAX_BLKS_IET;
	} else {
		val &= ~AM65_CPSW_PN_CTL_IET_PORT_EN;
		max_blks_val = AM65_CPSW_PN_MAX_BLKS_DEF;
	}

	writel(val, port->port_base + AM65_CPSW_PN_REG_CTL);
	writel(max_blks_val, port->port_base + AM65_CPSW_PN_REG_MAX_BLKS);
	port->iet_enabled = enable;
}

static int am65_cpsw_port_est_alloc_buf(struct net_device *ndev)
{
	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
	int active_buf, target_buf;
	u32 val;

	/* can't toggle buffer if prev. toggle is not completed */
	val = readl(port->port_base + AM65_CPSW_PN_REG_FIFO_STATUS);
	active_buf = !!(val & AM65_CPSW_PN_FST_EST_BUFACT);

	val = readl(port->port_base + AM65_CPSW_PN_REG_EST_CTL);
	target_buf = val & AM65_CPSW_PN_EST_BUFSEL;
	if (target_buf != active_buf) {
		dev_dbg(&ndev->dev, "Prev. buf toggle in transit %d -> %d\n",
			active_buf, target_buf);
		return -ENODATA;
	}

	return !active_buf;
}

/* target new EST RAM buffer, actual toggle happens after cycle completion */
static int am65_cpsw_port_est_target_buf(struct net_device *ndev, int idx)
{
	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
	u32 val;

	val = readl(port->port_base + AM65_CPSW_PN_REG_EST_CTL);
	if (idx)
		val |= AM65_CPSW_PN_EST_BUFSEL;
	else
		val &= ~AM65_CPSW_PN_EST_BUFSEL;

	writel(val, port->port_base + AM65_CPSW_PN_REG_EST_CTL);

	return 0;
}

static void am65_cpsw_est_set(struct net_device *ndev, int enable)
{
	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
	struct am65_cpsw_common *common = port->common;
	int common_enable = 0;
	int i;

	am65_cpsw_port_est_enable(port, enable);

	for (i = 0; i < common->port_num; i++)
		common_enable &= common->ports[i].est_enabled;

	am65_cpsw_est_enable(common, common_enable);
}

static void am65_cpsw_iet_set(struct net_device *ndev, int enable)
{
	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
	struct am65_cpsw_common *common = port->common;
	int common_enable = 0;
	int i;

	am65_cpsw_port_iet_enable(port, enable);

	for (i = 0; i < common->port_num; i++)
		common_enable &= common->ports[i].iet_enabled;

	am65_cpsw_iet_enable(common, common_enable);
}

static u32 am65_cpsw_est_calc_sched(struct net_device *ndev, int interval,
				    int gate_mask, int link_speed)
{
	u32 fetch_cnt, prio_mask;
	u64 temp;
	u32 sched;

	temp = interval * link_speed * 8;
	if (link_speed < SPEED_1000)
		temp <<= 1;

	fetch_cnt = DIV_ROUND_UP(temp, 1000);

	/* fetch count can't be less than 16? */
	if (fetch_cnt < 16)
		fetch_cnt = 16;

	if (fetch_cnt > AM65_CPSW_FETCH_CNT_MASK) {
		fetch_cnt &= AM65_CPSW_FETCH_CNT_MASK;
		dev_dbg(&ndev->dev, "fetch_cnt is more than 14 bits: %d\n",
			fetch_cnt);
	}

	if (gate_mask > AM65_CPSW_FETCH_ALLOW_MASK)
		dev_dbg(&ndev->dev, "fetch_allow is more than 8 bits: %d\n",
			fetch_cnt);

	prio_mask = gate_mask & AM65_CPSW_FETCH_ALLOW_MASK;
	sched = (fetch_cnt << AM65_CPSW_FETCH_CNT_SHIFT) & prio_mask;

	return sched;
}

static int am65_cpsw_est_set_cycle_scheds(struct net_device *ndev, int buf_idx,
					  struct tc_taprio_qopt_offload *taprio)
{
	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
	struct am65_cpsw_common *common = port->common;
	struct tc_taprio_sched_entry *entry;
	void __iomem *ram_base;
	int link_speed = 1000; /* const for now */
	u32 sched;
	int i;

	if (!taprio->enable)
		return 0;

	if (taprio->num_entries > AM65_CPSW_FETCH_CMD_NUM)
		return -EINVAL;

	ram_base = common->cpsw_base + AM65_CPSW_PORT_RAM_BASE +
		   AM65_CPSW_CPSW_PORT_RAM_OFFSET * (port->port_id - 1) +
		   buf_idx * AM65_CPSW_FETCH_CMD_NUM / 2;

	for (i = 0; i < taprio->num_entries; i++) {
		entry = &taprio->entries[i];
		sched = am65_cpsw_est_calc_sched(ndev, entry->interval,
						 entry->gate_mask, link_speed);

		writel(sched, ram_base + i * 4);
		printk(KERN_ERR "----> command = %d", entry->command);
		printk(KERN_ERR "----> interval = %d", entry->interval);
		printk(KERN_ERR "----> gate_mask = %d", entry->gate_mask);
	}

	return 0;
}

static int am65_cpsw_set_taprio(struct net_device *ndev, void *type_data)
{
	struct tc_taprio_qopt_offload *taprio = type_data;
	int ret, buf_idx;

	printk(KERN_ERR "--> base time = %lld", taprio->base_time);
	printk(KERN_ERR "--> cycle_time = %llu", taprio->cycle_time);
	printk(KERN_ERR "--> cycletime_ext = %llu", taprio->cycle_time_extension);

	buf_idx = am65_cpsw_port_est_alloc_buf(ndev);
	if (buf_idx < 0)
		return buf_idx;

	ret = am65_cpsw_est_set_cycle_scheds(ndev, buf_idx, taprio);
	if (ret)
		return ret;

	am65_cpsw_iet_set(ndev, taprio->frame_preemption);
	am65_cpsw_port_est_target_buf(ndev, buf_idx);
	am65_cpsw_est_set(ndev, taprio->enable);
	return 0;
}

static void am65_cpsw_est_ram_init(struct net_device *ndev)
{
	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
	u32 val;

	/* use two buffer operation to exchange configuration easily */
	val = AM65_CPSW_PN_EST_ONEBUF;
	writel(val, port->port_base + AM65_CPSW_PN_REG_EST_CTL);
}

int am65_cpsw_qos_ndo_setup_tc(struct net_device *ndev, enum tc_setup_type type,
			       void *type_data)
{
	switch (type) {
	case TC_SETUP_QDISC_TAPRIO:
		return am65_cpsw_set_taprio(ndev, type_data);

	default:
		return -EOPNOTSUPP;
	}
}

int am65_cpsw_qos_init(struct net_device *ndev)
{
	am65_cpsw_est_ram_init(ndev);
	return 0;
}
